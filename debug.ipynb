{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.zeros((3,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [[1, 2, 3], [3, 4, 5]]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'a': [[1,2,3], [3,4,5]]}\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [[1, 2], [3, 4, 5]]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['a'][0] = [1,2]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "my_dict = {'a': 1, 'b': 2, 'c': 3}\n",
    "value = next(iter(my_dict.values()))\n",
    "print(value)  # 输出 1 或 2 或 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [3, 32, 15, 7]\n",
    "num_tokens_to_remove = 20\n",
    "while num_tokens_to_remove:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9324193000793457\n",
      "[264, 265]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "num = 50000\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for _ in range(num):\n",
    "    lengths = [312, 267]\n",
    "    num_tokens_to_remove = 50\n",
    "    lengths_waiting_to_trunc = [lengths[i] for i in [0,1]]\n",
    "    for _ in range(num_tokens_to_remove):\n",
    "        index_max = lengths_waiting_to_trunc.index(max(lengths_waiting_to_trunc))\n",
    "        lengths_waiting_to_trunc[index_max] -= 1\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)\n",
    "print(lengths_waiting_to_trunc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.97226357460022\n",
      "[310, 267, 310, 267, 310, 267, 310, 267, 310, 267, 310, 267, 310, 267, 310, 267, 310, 267, 310, 267, 310, 267, 310, 267, 310, 267, 310, 267, 310, 267, 310, 267, 310, 267, 310, 267, 310, 267, 310, 267, 311, 267, 311, 267, 311, 267, 311, 267, 311, 267, 311, 267, 311, 267, 311, 267, 311, 267, 311, 267]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def argmax(l: list):\n",
    "    max_value_idx = 0\n",
    "    max_value = l[0]\n",
    "    idx = 1\n",
    "    while idx<len(l):\n",
    "        if max_value<l[idx]:\n",
    "            max_value, max_value_idx = l[idx], idx\n",
    "        idx += 1\n",
    "    return max_value_idx\n",
    "\n",
    "\n",
    "lengths = [312, 267]\n",
    "x = 50\n",
    "start = time.time()\n",
    "for _ in range(num):\n",
    "    lengths = [312, 267]*30\n",
    "    for _ in range(x):\n",
    "        max_index = argmax(lengths)\n",
    "        lengths[max_index] -= 1\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)\n",
    "print(lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.818470001220703\n",
      "[295 267 295 267 296 267]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "lengths = [312, 267]\n",
    "x = 50\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(num):\n",
    "    lengths = [312, 267]*3\n",
    "    for _ in range(x):\n",
    "        lengths = np.array(lengths)\n",
    "        max_index = np.argmax(lengths)\n",
    "        lengths[max_index] -= 1\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 2, 3, 6, 7, 8], 'ttt': [5, 4, 3, 6, 7, 8]}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def __truncate(tokenized_dict: dict[str, list[list]], waiting_to_trunc_idxs: list, num_tokens_to_remove: int) -> None:\n",
    "    lengths = [len(value_part) for value_part in tokenized_dict[\"input_ids\"]]\n",
    "    lengths_waiting_to_trunc = [lengths[i] for i in waiting_to_trunc_idxs]\n",
    "    for _ in range(num_tokens_to_remove):\n",
    "        index_max = lengths_waiting_to_trunc.index(max(lengths_waiting_to_trunc))\n",
    "        lengths_waiting_to_trunc[index_max] -= 1\n",
    "    print(lengths_waiting_to_trunc)\n",
    "    for i, j in zip(waiting_to_trunc_idxs, range(len(lengths_waiting_to_trunc))):\n",
    "        lengths[i] = lengths_waiting_to_trunc[j]\n",
    "    for value in tokenized_dict.values():\n",
    "        for i in waiting_to_trunc_idxs:\n",
    "            value[i] = value[i][: lengths[i]]\n",
    "\n",
    "cur_dict = {'input_ids':[[1,2,3,4,5], [6,7,8,9,0]], 'ttt': [[5,4,3,2,1], [6,7,8,9,0]]}\n",
    "__truncate(cur_dict, [0,1], 4)\n",
    "cur_dict\n",
    "cur_dict = {key: sum(value, []) for key, value in cur_dict.items()}\n",
    "cur_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [7592, 1010, 2129, 2024, 2017, 1012, 5292, 3270, 23644, 2050], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer('hello, how are you. hahahha', add_special_tokens=False)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = dict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [7592, 1010, 2129, 2024, 2017, 1012, 5292, 3270, 23644, 2050],\n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.pad(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfac12ec8ed49e6b1b5eff0d462f12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenize input texts:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from toolkit.nlp.dataset import TextDataset\n",
    "from transformers import AutoTokenizer\n",
    "import jsonlines\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "def get_data_from_file(data_file_path, model_type, tokenizer, is_train, **kargs):\n",
    "    special_tokens_map = tokenizer.special_tokens_map\n",
    "    BOS = special_tokens_map[\"bos_token\"] if \"bos_token\" in special_tokens_map.keys() else None\n",
    "    EOS = special_tokens_map[\"eos_token\"] if \"eos_token\" in special_tokens_map.keys() else None\n",
    "    SEP = special_tokens_map[\"sep_token\"] if \"sep_token\" in special_tokens_map.keys() else None\n",
    "    MASK = special_tokens_map[\"mask_token\"] if \"mask_token\" in special_tokens_map.keys() else None\n",
    "    CLS = special_tokens_map[\"cls_token\"] if \"cls_token\" in special_tokens_map.keys() else None\n",
    "    sep_num = 1\n",
    "\n",
    "    with jsonlines.open(data_file_path, \"r\") as jlReader:\n",
    "        dict_objs = list(jlReader)\n",
    "        if isinstance(dict_objs[0], str):\n",
    "            dict_objs = dict_objs[1:]\n",
    "\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    for dict_obj in dict_objs:\n",
    "        inputs.append((dict_obj[\"question1\"], dict_obj[\"question2\"]))\n",
    "        # input_texts.append(((False, CLS), (True, dict_obj[\"question1\"]), (False, SEP), (True, dict_obj[\"question2\"]), (False, SEP)))\n",
    "        labels.append([dict_obj[\"label\"]])\n",
    "        # labels.append(((False, CLS), (True, dict_obj[\"question1\"])))\n",
    "        # labels.append((dict_obj[\"question1\"], None))\n",
    "        # labels.append(dict_obj[\"question1\"])\n",
    "    return inputs, labels\n",
    "\n",
    "\n",
    "dataset = TextDataset(\n",
    "    \"test/data.jsonl\",\n",
    "    \"bert-base-uncased\",\n",
    "    tokenizer,\n",
    "    get_data_from_file=get_data_from_file,\n",
    "    padding_side=\"left\",\n",
    "    max_length_input=20,\n",
    "    max_length_label=22,\n",
    "    is_train=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_input': {'input_ids': tensor([ 101, 1045, 2215, 2000, 7323, 8065, 1999, 3274, 2671,  102, 1045, 5047,\n",
      "        2591, 2865, 2005, 1037, 2512, 1011, 5618,  102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}, 'first_not_pad_index_input': tensor(0), 'labels': tensor([0], dtype=torch.int32)}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "1\n",
      "[CLS] i want to pursue phd in computer science [SEP] i handle social media for a non - profit [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.max_length_inputs)\n",
    "print(dataset.max_length_labels)\n",
    "print(tokenizer.decode(dataset[1]['model_input']['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 20])\n",
      "torch.Size([4, 20])\n",
      "torch.Size([4, 20])\n",
      "torch.Size([4, 20])\n",
      "torch.Size([4, 20])\n",
      "torch.Size([4, 20])\n",
      "torch.Size([4, 20])\n",
      "torch.Size([4, 20])\n",
      "{'labels': tensor([[  101,  2054,  2024,  1996,  5918,  2000,  2468,  2343,  1999,  1996,\n",
      "          2142,  2163,  1998,  2129,  2024,  1996,  5918,  2367,  1999, 11959,\n",
      "          1029,   102],\n",
      "        [  101,  1000,  2040,  2003,  1996,  4205,  1996,  4581,  2000, 12373,\n",
      "          1011, 17691,  1005,  1055,  1000,  1000,  4205,  1005,  1055,  2299,\n",
      "          1000,   102],\n",
      "        [  101,  2054,  2808,  2323,  1045,  3191,  2004,  2019, 22344, 10670,\n",
      "          1029,   102,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100],\n",
      "        [  101,  2339,  2515,  1037, 10098, 18669, 20553,  2102,  2191,  1037,\n",
      "          2204,  9004,  1029,   102,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100]]), 'input_ids': tensor([[  101,  2054,  2024,  1996,  5918,  2000,  2468,  2343,  1999,   102,\n",
      "          2054,  2024,  1996,  5918,  2000,  2468,  2343,  1999,  1996,   102],\n",
      "        [  101,  1000,  2040,  2003,  1996,  4205,  1996,  4581,  2000, 12373,\n",
      "           102,  1000,  2029, 12373,  1011, 17691,  2316,  2266,  2626,   102],\n",
      "        [  101,  2054,  2808,  2323,  1045,  3191,  2004,  2019, 22344,   102,\n",
      "          2054,  2024,  1996,  2327,  2808,  2019, 22344,  9458, 10670,   102],\n",
      "        [  101,  2339,  2515,  1037, 10098, 18669, 20553,  2102,  2191,   102,\n",
      "          2064, 18669, 20553,  3215,  2022,  2204, 18551,  1029,  2054,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, default_collate\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=False, \n",
    "                        collate_fn=dataset.collate_fn_padding_right if dataset.padding_side=='right' else dataset.collate_fn_padding_left, \n",
    "                        pin_memory=True)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch['input_ids'].shape)\n",
    "    # print(batch['labels'].shape)\n",
    "    # print(batch['input_ids'].is_pinned())\n",
    "    # print(batch)\n",
    "    # break\n",
    "\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': tensor([[1, 2, 3],\n",
       "         [1, 2, 3]]),\n",
       " 'b': tensor([[4, 5, 6],\n",
       "         [4, 5, 6]]),\n",
       " 'c': ['hh', 'hh']}"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, default_collate\n",
    "\n",
    "default_collate([{'a': torch.tensor([1,2,3]), 'b': torch.tensor([4,5,6]), 'c':'h' 'h'}, {'a': torch.tensor([1,2,3]), 'b': torch.tensor([4,5,6]), 'c':'h' 'h'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PretrainedConfig, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.__dict__: {'model_type': '', 'model_name': '', '_name_or_path': '', 'return_dict': True}\n",
      "{'model_type': '', 'model_name': '', '_name_or_path': '', 'return_dict': True}\n",
      "{'return_dict': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from toolkit import Config\n",
    "# Config.attribute_alias_map = {'return_dict': 'retrundict'}\n",
    "t = Config(return_dict=True)\n",
    "\n",
    "print(f\"self.__dict__: {t.__dict__}\")\n",
    "print(t.to_dict())\n",
    "print(t.to_diff_dict())\n",
    "t.return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-30 09:21:32,462 - \u001b[32m INFO > toolkit.configuration: Configuration saved in config/train_config.json\u001b[0m\n",
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NLPTrainConfig {\n",
       "  \"a_unknow\": \"aaa\",\n",
       "  \"accumulate_step\": 1,\n",
       "  \"adam_epsilon\": 1e-08,\n",
       "  \"batch_size\": \"baseline\",\n",
       "  \"dataset\": \"QQP\",\n",
       "  \"early_stop\": false,\n",
       "  \"early_stop_metric\": \"acc\",\n",
       "  \"epochs\": \"bert-base-uncase\",\n",
       "  \"fp16\": false,\n",
       "  \"learning_rate\": 5,\n",
       "  \"max_length_input\": 256,\n",
       "  \"max_length_label\": null,\n",
       "  \"model_name\": 3e-05,\n",
       "  \"model_type\": 32,\n",
       "  \"problem_type\": null,\n",
       "  \"seed\": 0,\n",
       "  \"test_in_epoch\": false,\n",
       "  \"warmup\": false,\n",
       "  \"warmup_ratio\": -1,\n",
       "  \"weight_decay\": 0.01\n",
       "}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from toolkit.nlp import NLPTrainConfig\n",
    "\n",
    "kwargs = {\n",
    "    \"dataset\":'QQP',\n",
    "    \"early_stop_metric\": 'acc',\n",
    "    \"model_type\": \"bert-base-uncase\",\n",
    "    \"model_name\": \"baseline\",\n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 3e-5,\n",
    "    \"a_unknow\": 'aaa',\n",
    "    \"max_length_input\":256\n",
    "}\n",
    "tt = NLPTrainConfig(**kwargs)\n",
    "tt.save_pretrained('config')\n",
    "print(tt.model_type)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-30 09:21:33,879 - \u001b[32m INFO > toolkit.configuration: loading configuration file config/train_config.json\u001b[0m\n",
      "False\n",
      "NLPTrainConfig {\n",
      "  \"a_unknow\": \"aaa\",\n",
      "  \"accumulate_step\": 1,\n",
      "  \"adam_epsilon\": 1e-08,\n",
      "  \"batch_size\": 3e-05,\n",
      "  \"dataset\": \"QQP\",\n",
      "  \"early_stop\": false,\n",
      "  \"early_stop_metric\": \"acc\",\n",
      "  \"epochs\": 32,\n",
      "  \"fp16\": false,\n",
      "  \"learning_rate\": \"bert-base-uncase\",\n",
      "  \"max_length_input\": 256,\n",
      "  \"max_length_label\": null,\n",
      "  \"model_name\": 5,\n",
      "  \"model_type\": \"baseline\",\n",
      "  \"problem_type\": null,\n",
      "  \"seed\": 0,\n",
      "  \"test_in_epoch\": false,\n",
      "  \"warmup\": false,\n",
      "  \"warmup_ratio\": -1,\n",
      "  \"weight_decay\": 0.01\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_load = NLPTrainConfig.from_pretrained('train_config.json')\n",
    "print(tt==tt_load)\n",
    "print(tt_load)\n",
    "tt.max_length_input is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert\n",
      "{'_name_or_path': '', 'train_return_dict': False, 'ttt': 2, 'model_type': 'bert'}\n",
      "base:        {'_name_or_path': '', 'model_type': ''}\n",
      "class specific: {'_name_or_path': '', 'train_return_dict': False, 'ttt': 1, 'model_type': 'bert'}\n",
      "{'train_return_dict': False, 'ttt': 2, 'model_type': 'bert'}\n"
     ]
    }
   ],
   "source": [
    "class TrainConfig(Config):\n",
    "    model_type='bert'\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.train_return_dict = False\n",
    "        self.ttt = 1\n",
    "\n",
    "st = TrainConfig()\n",
    "print(st.model_type)\n",
    "st.ttt=2\n",
    "print(st.to_dict())\n",
    "print(st.to_diff_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainConfig.from_pretrained('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attribute_alias_map\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'return_dict': 'retrundict'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.attribute_alias_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_dict\n",
      "retrundict\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrundict\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.retrundict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jjwang/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "class Path(os.PathLike):\n",
    "    def __init__(self, path):\n",
    "        self.__path = path\n",
    "\n",
    "    def __fspath__(self):\n",
    "        return self.__path.replace(\"/\", os.path.sep)\n",
    "\n",
    "    \n",
    "path = Path('/home/jjwang/')\n",
    "print(path.__fspath__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path('./test/data.jsonl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "复杂推理是指理解和利用支持证据或逻辑得出结论或做出决定的能力[51,52]。\n",
      "根据推理过程中涉及的逻辑和证据的类型，将现有的评估任务分为知识推理、符号推理和数学推理3大类。\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"\"\"\n",
    "复杂推理是指理解和利用支持证据或逻辑得出结论或做出决定的能力[51,52]。根据推理过程中涉及的逻辑和证据的类型，将现有的评估任务分为知识推理、符号推理和数学推理3大类。\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "text = re.sub(r'。', '。\\n', text)\n",
    "text = re.sub(r'\\(', '（', text)\n",
    "text = re.sub(r'\\)', '）', text)\n",
    "text = re.sub(r'llm', 'LLM', text)\n",
    "text = re.sub(r'plm', 'PLM', text)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "p = Path('setup.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('config/setup.cfg')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'config'/p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def check_mem(cuda_device_id: int)->tuple[int,int]:\n",
    "    \"\"\"Get total and used memory (unit: `MB`) of GPU with the corresponding ID.\"\"\"\n",
    "    devices_info = os.popen('\"/usr/bin/nvidia-smi\" --query-gpu=memory.total,memory.used --format=csv,nounits,noheader').read().strip().split(\"\\n\")\n",
    "    total, used = devices_info[int(cuda_device_id)].split(\",\")\n",
    "    return int(total), int(used)\n",
    "\n",
    "check_mem(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 函数设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import math\n",
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "def log_func(x, n):\n",
    "    n = torch.tensor(n)\n",
    "    return torch.log(x)/torch.log(n)\n",
    "\n",
    "\n",
    "# def randomcolor():\n",
    "#     colorArr = [ '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F' ]\n",
    "#     color = \"\"\n",
    "#     for i in range (6):\n",
    "#         color += colorArr[random.randint (0, 14)]\n",
    "#     return \"#\" +color\n",
    "\n",
    "\n",
    "def randomcolor():\n",
    "    colorArr = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F' ]\n",
    "    color = \"\"\n",
    "    for i in range(6):\n",
    "        color += colorArr[random.randint(0, 15)]\n",
    "    return \"#\"+color\n",
    "\n",
    "\n",
    "# plt.rc('font',family='HYZhengYuan')\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['axes.unicode_minus']=False #用来正常显示负号\n",
    "\n",
    "logits = torch.tensor([list(np.linspace(-10, 10, 1000, endpoint=True))], dtype=torch.float).T\n",
    "labels_pos = torch.ones((logits.shape[0], 1), dtype=int)\n",
    "labels_neg = torch.zeros((logits.shape[0], 1), dtype=int)\n",
    "y = torch.sigmoid(logits).detach()\n",
    "\n",
    "\n",
    "\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "# alpha = -0.5\n",
    "# beta = 10\n",
    "# weight_loss1 = torch.ones((logits.shape[0], 1), device=logits.device)\n",
    "# already_classable = ((logits>0)==labels).squeeze()\n",
    "# weight_loss1[already_classable] = torch.sigmoid(((abs(labels-y).detach()+alpha)[already_classable])*beta)\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "alpha = 0\n",
    "beta = 2\n",
    "gama = 0.9\n",
    "delta = 1-gama\n",
    "weight_loss2_10 = torch.ones((logits.shape[0], 1), device=logits.device)\n",
    "already_classable = ((logits>0)==labels_pos).squeeze()\n",
    "x = ((abs(labels_pos-y).detach()+alpha)*beta)[already_classable]*gama  # x: [game, 0]\n",
    "# print(x[0], x[-1])\n",
    "x = gama-x+delta\n",
    "# print(x[0], x[-1])\n",
    "# weight_loss2[already_classable] = torch.log(((abs(labels-y).detach()+alpha)[already_classable])*beta)+1\n",
    "weight_loss2_10[already_classable] = -torch.log10(x)\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "alpha = 0\n",
    "beta = 2\n",
    "gama = 0.5\n",
    "delta = 1-gama\n",
    "weight_loss2_2 = torch.ones((logits.shape[0], 1), device=logits.device)\n",
    "already_classable = ((logits>0)==labels_pos).squeeze()\n",
    "x = ((abs(labels_pos-y).detach()+alpha)*beta)[already_classable]*gama  # x: [game, 0]\n",
    "# print(x[0], x[-1])\n",
    "x = gama-x+delta\n",
    "# print(x[0], x[-1])\n",
    "# weight_loss2[already_classable] = torch.log(((abs(labels-y).detach()+alpha)[already_classable])*beta)+1\n",
    "weight_loss2_2[already_classable] = -torch.log2(x)\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "# base=100\n",
    "\n",
    "# alpha = 0\n",
    "# beta = 2\n",
    "# gama = 1-1/base\n",
    "# delta = 1-gama\n",
    "# weight_loss2_n = torch.ones((logits.shape[0], 1), device=logits.device)\n",
    "# already_classable = ((logits>0)==labels).squeeze()\n",
    "# x = ((abs(labels-y).detach()+alpha)*beta)[already_classable]*gama  # x: [game, 0]\n",
    "# # print(x[0], x[-1])\n",
    "# x = gama-x+delta\n",
    "# # print(x[0], x[-1])\n",
    "# # weight_loss2[already_classable] = torch.log(((abs(labels-y).detach()+alpha)[already_classable])*beta)+1\n",
    "# weight_loss2_n[already_classable] = -log(x, base)\n",
    "\n",
    "base=1000\n",
    "def get_weights_loss(logits, labels, base):\n",
    "    logits = logits.detach()\n",
    "    labels = labels.detach()\n",
    "    y = torch.sigmoid(logits)\n",
    "    gama = 1-1/base\n",
    "    weight_loss = torch.ones((logits.shape[0], 1), device=logits.device)\n",
    "    already_classable = ((logits>0)==labels.bool()).squeeze()\n",
    "    x = (abs(labels-y)*2)[already_classable]*(gama)  # x: [game, 0]\n",
    "    x = 1-x\n",
    "    weight_loss[already_classable] = -log_func(x, base)\n",
    "    return weight_loss\n",
    "weight_loss2_n = get_weights_loss(logits, labels_pos, base)\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "# alpha = 0\n",
    "# beta = 2\n",
    "# gama = 5\n",
    "# weight_loss3 = torch.ones((logits.shape[0], 1), device=logits.device)\n",
    "# already_classable = ((logits>0)==labels).squeeze()\n",
    "# x = ((abs(labels-y).detach()+alpha)*beta)[already_classable]*gama\n",
    "# weight_loss3[already_classable] = -(torch.tanh(gama-x))+1\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Increase font size\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "# Use consistent line width and style\n",
    "line_style = {'linewidth': 1.25, 'linestyle': '-'}\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "# plt.rcParams['font.serif'] = ['CMU Serif'] + plt.rcParams['font.serif']\n",
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "plt.rcParams['xtick.major.width'] = 0.5\n",
    "plt.rcParams['ytick.major.width'] = 0.5\n",
    "plt.rcParams['lines.linewidth'] = 1.25\n",
    "\n",
    "# Use a pastel color scheme\n",
    "# colors = sns.color_palette('husl', 4)\n",
    "colors = sns.color_palette(\"Greens\", 4)\n",
    "# colors = sns.dark_palette(\"Greens\", 4, reverse=True)\n",
    "# colors = sns.dark_palette(\"deep\", 4, reverse=True)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 4), dpi=300)\n",
    "\n",
    "# Plot the positive labels\n",
    "for i, log in enumerate([2, 10, 100, 1000]):\n",
    "    ax1.plot(y, get_weights_loss(logits, labels_pos, log), color=colors[i], label=f'log {log}', **line_style)\n",
    "\n",
    "# # Improve axis labels\n",
    "# ax1.set_xlabel('Probability of prediction')\n",
    "# ax1.set_ylabel('Weight')\n",
    "\n",
    "# # Simplify the legend\n",
    "# ax1.legend(loc='upper right', frameon=False)\n",
    "\n",
    "# Plot the negative labels\n",
    "for i, log in enumerate([2, 10, 100, 1000]):\n",
    "    ax2.plot(y, get_weights_loss(logits, labels_neg, log), color=colors[i], label=f'log {log}', **line_style)\n",
    "\n",
    "# # Improve axis labels\n",
    "# ax2.set_xlabel('Probability of prediction')\n",
    "# ax2.set_ylabel('Weight')\n",
    "\n",
    "# # Simplify the legend\n",
    "# ax2.legend(loc='upper left', frameon=False)\n",
    "\n",
    "# Remove top and right borders\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Increase line width of remaining borders\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.spines['left'].set_linewidth(1.5)\n",
    "    ax.spines['bottom'].set_linewidth(1.5)\n",
    "\n",
    "# Add a title\n",
    "# fig.suptitle('Weighted Loss vs Probability of Prediction')\n",
    "\n",
    "# Add a grid\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.grid(True, linestyle='-', alpha=0.8)\n",
    "    # ax.grid(axis='y', linestyle=':', alpha=0.7)\n",
    "\n",
    "# Improve axis labels\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.set_xlabel('Probability of prediction')\n",
    "    ax.set_ylabel('Weight')\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.legend(loc='best', frameon=False)\n",
    "\n",
    "# Adjust aspect ratio\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"function.eps\", format='eps', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 折线图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.font_manager import FontProperties\n",
    "# 数据\n",
    "x = [i*1000 for i in range(1,5)]\n",
    "baseline_no_prompt_acc_mean_5 = [83.63999938964844,84.23999938964843,86.2,86.64000091552734]\n",
    "baseline_acc_mean_5 = [83.15999908447266,85.44000091552735,86.28000183105469,86.51999969482422]\n",
    "ensemble_acc_mean_5 = [85.68000183105468,87.6,87.16000061035156,87.96000061035156]\n",
    "baseline_no_prompt_f1_mean_5 = [79.65749969482422,80.31880798339844,82.51792449951172,82.95933532714844]\n",
    "baseline_f1_mean_5 = [79.35353546142578,81.92408599853516,82.49300231933594,82.68881683349609]\n",
    "ensemble_f1_mean_5 = [81.37353973388672,83.64531707763672,82.87378692626953,84.07548522949219]\n",
    "\n",
    "\n",
    "# 设置图形参数\n",
    "# font = FontProperties(fname='/home/jjwang/.fonts/cmunrm.ttf')\n",
    "# plt.rcParams['font.family'] = font.get_name()\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "# plt.rcParams['font.serif'] = ['CMU Serif'] + plt.rcParams['font.serif']\n",
    "# plt.rcParams['font.serif'] = 'Times New Roman'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
    "print(plt.rcParams['font.serif'])\n",
    "# plt.rc('font', family='CMU Serif')\n",
    "plt.rcParams['font.size'] = 8\n",
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "plt.rcParams['xtick.major.width'] = 0.5\n",
    "plt.rcParams['ytick.major.width'] = 0.5\n",
    "plt.rcParams['lines.linewidth'] = 1.25\n",
    "\n",
    "\n",
    "# Use a pastel color scheme\n",
    "colors = sns.color_palette(\"Spectral\", 2)\n",
    "colors = sns.color_palette(\"husl\", 2)\n",
    "colors2 = sns.color_palette(\"Greens\", 2)\n",
    "colors = [colors[1], colors2[1]]\n",
    "colors = ['#37B971', '#ADD71B']\n",
    "# colors = sns.dark_palette(\"Greens\", 4, reverse=True)\n",
    "# colors = sns.dark_palette(\"deep\", 4, reverse=True)\n",
    "\n",
    "\n",
    "# 创建图形\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(9, 2.5), dpi=300)\n",
    "\n",
    "# 绘制Accuracy子图\n",
    "# ax1.plot(x, baseline_no_prompt_acc_mean_5, 'v-', color='tab:red', label='Baseline_no_prompt')\n",
    "# ax1.plot(x, baseline_acc_mean_5, 'o-', color='tab:blue', label='Baseline')\n",
    "# ax1.plot(x, ensemble_acc_mean_5, 'D-', color='tab:green', label='With describe')\n",
    "ax1.axhline(y=81.875, linestyle='--', color='red', label='ChatGPT Zeroshot')\n",
    "ax1.plot(x, baseline_acc_mean_5, 'o-', color=colors[0], label='Baseline')\n",
    "ax1.plot(x, ensemble_acc_mean_5, 'D-', color=colors[1], label='With Distinctions')\n",
    "ax1.set_xlabel('Number of Training Examples')\n",
    "ax1.set_ylabel('Accuracy (%)')\n",
    "# ax1.legend(loc='lower right')\n",
    "# ax1.grid(axis='y', linestyle='-', alpha=0.8)\n",
    "# 绘制F1-Score子图\n",
    "# ax2.plot(x, baseline_no_prompt_f1_mean_5, 'v-', color='tab:red', label='Baseline_no_prompt')\n",
    "ax2.axhline(y=75.65480188045667, linestyle='--', color='red', label='ChatGPT Zeroshot')\n",
    "ax2.plot(x, baseline_f1_mean_5, 'o-', color=colors[0], label='Baseline')\n",
    "ax2.plot(x, ensemble_f1_mean_5, 'D-', color=colors[1], label='With Distinctions')\n",
    "ax2.set_xlabel('Number of Training Examples')\n",
    "ax2.set_ylabel('F1-Score (%)')\n",
    "# ax2.legend(loc='lower right')\n",
    "# ax2.grid(axis='y', linestyle='-', alpha=0.8)\n",
    "# 调整子图间距和布局\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "\n",
    "for ax in (ax1, ax2):\n",
    "    ax.grid(axis='y', linestyle='-', alpha=0.8)\n",
    "    ax.legend(loc='lower right', bbox_to_anchor=(1, 0.05))\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    # ax.spines['bottom'].set_linewidth(2)\n",
    "    # ax.spines['left'].set_linewidth(2)\n",
    "# 保存图形\n",
    "# fig.savefig('subplots.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"gpt.eps\", format='eps', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rouge-L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.text.rouge import rouge_score\n",
    "\n",
    "\n",
    "all_rougeL = []\n",
    "neg_rougel = []\n",
    "pos_rougel = []\n",
    "lines = [\n",
    "    '头发多适合剪短发吗   头发少适合剪短吗    0', \n",
    "    '今天北京下雨了吗   今天北京会下雨吗    0', \n",
    "    '刚出生的小野鸡怎么养   刚抓来的野鸡怎么养    0', \n",
    "    '刚出生的小野鸡怎么养\t刚抓来的野鸡怎么养殖  0', \n",
    "    '温州有什么好玩的地方？ 温州什么地方最好玩  0',\n",
    "    '今晚吃什么    篮球好玩吗   0', \n",
    "    '这姑娘漂亮不   我姑娘漂亮吧    0', \n",
    "    '意大利面怎么做   意大利面怎么煮的快  0', \n",
    "    '瞻仰的瞻是什么意思   瞻仰的仰是什么意思？！ 0', \n",
    "    '仰望的仰是什么意思   瞻仰的仰是什么意思 0', \n",
    "    '赵县梨花什么时候开 赵县梨花节什么时候啊？ 0', \n",
    "    '晚安日语怎么写？ 晚安用日语怎么说 0',\n",
    "    ]\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    s1, s2, label = line.split()\n",
    "    lable = int(label)\n",
    "    rougeL = rouge_score(s1, s2, rouge_keys='rougeL', tokenizer=list, normalizer=lambda x: x)['rougeL_fmeasure'].item()\n",
    "    all_rougeL.append(rougeL)\n",
    "    if lable==1:\n",
    "        pos_rougel.append(rougeL)\n",
    "    else:\n",
    "        neg_rougel.append(rougeL)\n",
    "    print(f\"{s1}\\t{s2}\\t{rougeL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "lines = [\n",
    "    '头发多适合剪短发吗   头发少适合剪短吗    0', \n",
    "    '今天北京下雨了吗   今天北京会下雨吗    0', \n",
    "    '刚出生的小野鸡怎么养   刚抓来的野鸡怎么养    0', \n",
    "    '刚出生的小野鸡怎么养\t刚抓来的野鸡怎么养殖  0', \n",
    "    '温州有什么好玩的地方？ 温州什么地方最好玩  0',\n",
    "    '今晚吃什么    篮球好玩吗   0', \n",
    "    '这姑娘漂亮不   我姑娘漂亮吧    0', \n",
    "    '意大利面怎么做   意大利面怎么煮的快  0', \n",
    "    '瞻仰的瞻是什么意思   瞻仰的仰是什么意思？！ 0', \n",
    "    '仰望的仰是什么意思   瞻仰的仰是什么意思 0', \n",
    "    '赵县梨花什么时候开 赵县梨花节什么时候啊？ 0', \n",
    "    '晚安日语怎么写？ 晚安用日语怎么说 0',\n",
    "    ]\n",
    "\n",
    "\n",
    "all_lr = []\n",
    "neg_lr = []\n",
    "pos_lr = []\n",
    "\n",
    "for line in lines:\n",
    "    s1, s2, label = line.split()\n",
    "    lable = int(label)\n",
    "    lr = Levenshtein.ratio(s1, s2)\n",
    "    all_lr.append(lr)\n",
    "    if lable==1:\n",
    "        pos_lr.append(lr)\n",
    "    else:\n",
    "        neg_lr.append(lr)\n",
    "    print(f\"{s1}\\t{s2}\\t{lr}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = 'qnli'\n",
    "dataset = load_dataset(\"glue\", dataset_name)\n",
    "# you can use any of the following config names as a second argument:\n",
    "\"ax\", \"cola\", \"mnli\", \"mnli_matched\", \n",
    "\"mnli_mismatched\", \"mrpc\", \"qnli\", \"qqp\", \n",
    "\"rte\", \"sst2\", \"stsb\", \"wnli\"\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "for key in dataset['train'].features.keys():\n",
    "    pprint(f\"{key}: {dataset['train'][key][:10]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import os\n",
    "from tqdm.auto import trange\n",
    "dataset_name = dataset_name.upper()\n",
    "splits = dataset.keys()\n",
    "# split = 'validation'\n",
    "for split in splits:\n",
    "    output_path = f\"data/{dataset_name}/{split}\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    with jsonlines.open(os.path.join(output_path, 'all.jsonl'), 'w') as jlWriter:\n",
    "        objs = []\n",
    "        keys = list(dataset[split].features.keys())\n",
    "        data_dict = {key:dataset[split][key] for key in keys}\n",
    "        for i in trange(dataset[split].num_rows):\n",
    "            objs.append({key:data_dict[key][i] for key in keys})\n",
    "        jlWriter.write_all(objs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [(int, int), (int, int)], 'b': [int, int, int]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, List, Tuple, Union\n",
    "\n",
    "def get_data_types(data: Union[List, Tuple, Any]) -> Union[type, List, Tuple]:\n",
    "    \"\"\"\n",
    "    获取一个嵌套结构中的所有数据类型，并保留嵌套结构\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        return {k: get_data_types(v) for k, v in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [get_data_types(item) for item in data]\n",
    "    elif isinstance(data, tuple):\n",
    "        return tuple(get_data_types(item) for item in data)\n",
    "    else:\n",
    "        return type(data)\n",
    "    \n",
    "data = {'a':[(1, 2), (3, 4)], 'b':[1,2,3]}\n",
    "get_data_types(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 'List[Tuple[int, int], Tuple[int, int]]', 'b': 'List[int, int, int]'}\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, List, Tuple, Dict\n",
    "\n",
    "def type_to_str(data):\n",
    "    return str(type(data))[8:-2]\n",
    "def get_data_types(data: List| Tuple| Any) -> str|Dict[Any,str]:\n",
    "    \"\"\"\n",
    "    获取一个嵌套结构中的所有数据类型，并保留嵌套结构\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        return {k: get_data_types(v) for k, v in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return f\"List[{', '.join([get_data_types(item) for item in data])}]\"\n",
    "    elif isinstance(data, tuple):\n",
    "        return f\"Tuple[{', '.join([get_data_types(item) for item in data])}]\"\n",
    "    else:\n",
    "        return type_to_str(data)\n",
    "    \n",
    "data = {'a':[(1, 2), (3, 4)], 'b':[1,2,3]}\n",
    "# data = [(1, 2), (3, 4)]\n",
    "# data = [1,2,3]\n",
    "print(get_data_types(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def type_to_str(data):\n",
    "    return str(type(data))[8:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NoneType'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_to_str(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
